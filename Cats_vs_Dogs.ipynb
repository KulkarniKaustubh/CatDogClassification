{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as K\n",
    "from tensorflow.keras.layers import Conv2D, Dense, MaxPooling2D, Flatten, BatchNormalization, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# all directories\n",
    "TRAIN_DIR = 'extracted/cats_and_dogs_filtered/train'\n",
    "VAL_DIR = 'extracted/cats_and_dogs_filtered/validation'\n",
    "TRAIN_DIR_CATS = 'extracted/cats_and_dogs_filtered/train/cats'\n",
    "TRAIN_DIR_DOGS = 'extracted/cats_and_dogs_filtered/train/dogs'\n",
    "VAL_DIR_CATS = 'extracted/cats_and_dogs_filtered/validation/cats'\n",
    "VAL_DIR_DOGS = 'extracted/cats_and_dogs_filtered/validation/dogs'\n",
    "\n",
    "# getting images squared\n",
    "imageSize = 50\n",
    "\n",
    "# alpha\n",
    "lr = 0.001\n",
    "\n",
    "# momentum\n",
    "beta_1 = 0.9\n",
    "\n",
    "# mini-batch size\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# number of epochs\n",
    "epochs = 10\n",
    "\n",
    "# total training data and val data\n",
    "totalTrain = len(os.listdir(TRAIN_DIR_CATS))\n",
    "totalTrain += len(os.listdir(TRAIN_DIR_DOGS))\n",
    "\n",
    "totalVal = len(os.listdir(VAL_DIR_CATS))\n",
    "totalVal += len(os.listdir(VAL_DIR_DOGS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data augmentation since we have a small training set\n",
    "trainImageGenerator = ImageDataGenerator(\n",
    "                                        rescale = 1./255.,  # normalization\n",
    "                                        rotation_range = 40,  # range of rotation\n",
    "                                        width_shift_range = 0.2,\n",
    "                                        height_shift_range = 0.2,\n",
    "                                        shear_range = 0.2,\n",
    "                                        zoom_range = 0.2,\n",
    "                                        horizontal_flip = True,  # fliiping images horizontally\n",
    "                                        fill_mode = 'nearest'  # any pixel gaps will be filled with the 'nearest' pizel\n",
    "                                        )\n",
    "\n",
    "validationImageGenerator = ImageDataGenerator(\n",
    "                                        rescale = 1./255.\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# declaring training data\n",
    "trainingData = trainImageGenerator.flow_from_directory(\n",
    "                                        batch_size = BATCH_SIZE,\n",
    "                                        directory = TRAIN_DIR,\n",
    "                                        shuffle = True,\n",
    "                                        target_size = (imageSize, imageSize),\n",
    "                                        class_mode = 'binary'   # only cats or dogs, binary classification\n",
    "                                        )\n",
    "\n",
    "validationData = validationImageGenerator.flow_from_directory(\n",
    "                                        batch_size = BATCH_SIZE,\n",
    "                                        directory = VAL_DIR,\n",
    "                                        shuffle = False,\n",
    "                                        target_size = (imageSize, imageSize),\n",
    "                                        class_mode = 'binary'\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cats': 0, 'dogs': 1}\n"
     ]
    }
   ],
   "source": [
    "# printing classes\n",
    "print(trainingData.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clearing previous models\n",
    "K.backend.clear_session()\n",
    "\n",
    "# defining the model\n",
    "model = K.models.Sequential([\n",
    "    Conv2D(filters = 32, kernel_size = (3, 3), activation = 'relu', input_shape = (imageSize, imageSize, 3)), # 3 for RGB\n",
    "    MaxPooling2D(pool_size = (2, 2)),\n",
    "    \n",
    "    Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'),\n",
    "    MaxPooling2D(pool_size = (2, 2)),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Conv2D(filters = 128, kernel_size = (3, 3), activation = 'relu'),\n",
    "    MaxPooling2D(pool_size = (2, 2)),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Conv2D(filters = 128, kernel_size = (3, 3), activation = 'relu'),\n",
    "    MaxPooling2D(pool_size = (2, 2)),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Dropout(rate = 0.5),        # regularization to reduce variance\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(units = 256, activation = 'relu'),\n",
    "    \n",
    "    Dense(units = 2, activation = 'softmax')\n",
    "    \n",
    "], name = 'cats-vs-dogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "model.compile (\n",
    "    optimizer = 'adam',\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cats-vs-dogs\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 11, 11, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1, 1, 128)         512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 275,650\n",
      "Trainable params: 275,010\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.7922 - accuracy: 0.5505WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 63 batches). You may need to use the repeat() function when building your dataset.\n",
      "63/63 [==============================] - 16s 248ms/step - loss: 0.7922 - accuracy: 0.5505 - val_loss: 0.6989 - val_accuracy: 0.4900\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.7460 - accuracy: 0.5675 ETA: 3s -WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 63 batches). You may need to use the repeat() function when building your dataset.\n",
      "63/63 [==============================] - 16s 256ms/step - loss: 0.7460 - accuracy: 0.5675 - val_loss: 0.7118 - val_accuracy: 0.5090\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.7260 - accuracy: 0.5780WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 63 batches). You may need to use the repeat() function when building your dataset.\n",
      "63/63 [==============================] - 18s 279ms/step - loss: 0.7260 - accuracy: 0.5780 - val_loss: 0.7648 - val_accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.7154 - accuracy: 0.5750WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 63 batches). You may need to use the repeat() function when building your dataset.\n",
      "63/63 [==============================] - 15s 241ms/step - loss: 0.7154 - accuracy: 0.5750 - val_loss: 0.6773 - val_accuracy: 0.5760\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.7024 - accuracy: 0.5860WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 63 batches). You may need to use the repeat() function when building your dataset.\n",
      "63/63 [==============================] - 15s 236ms/step - loss: 0.7024 - accuracy: 0.5860 - val_loss: 0.8246 - val_accuracy: 0.5050\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6804 - accuracy: 0.5930WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 63 batches). You may need to use the repeat() function when building your dataset.\n",
      "63/63 [==============================] - 15s 234ms/step - loss: 0.6804 - accuracy: 0.5930 - val_loss: 0.8059 - val_accuracy: 0.5070\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6653 - accuracy: 0.6110WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 63 batches). You may need to use the repeat() function when building your dataset.\n",
      "63/63 [==============================] - 15s 237ms/step - loss: 0.6653 - accuracy: 0.6110 - val_loss: 0.6853 - val_accuracy: 0.5680\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6765 - accuracy: 0.6075WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 63 batches). You may need to use the repeat() function when building your dataset.\n",
      "63/63 [==============================] - 18s 280ms/step - loss: 0.6765 - accuracy: 0.6075 - val_loss: 0.7156 - val_accuracy: 0.5560\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6622 - accuracy: 0.6180WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 63 batches). You may need to use the repeat() function when building your dataset.\n",
      "63/63 [==============================] - 14s 230ms/step - loss: 0.6622 - accuracy: 0.6180 - val_loss: 0.7504 - val_accuracy: 0.5620\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6565 - accuracy: 0.6355WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 63 batches). You may need to use the repeat() function when building your dataset.\n",
      "63/63 [==============================] - 15s 231ms/step - loss: 0.6565 - accuracy: 0.6355 - val_loss: 0.6429 - val_accuracy: 0.6180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efe18159250>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit is overloaded with fit_generator in TensorFlow 2.2+, hence, using fit\n",
    "model.fit(\n",
    "    trainingData,\n",
    "    steps_per_epoch = int(np.ceil(totalTrain / float(BATCH_SIZE))),  # steps per epoch is defined as total by batch size\n",
    "    epochs = epochs,\n",
    "    validation_data = validationData,\n",
    "    validation_steps = int(np.ceil(totalTrain / float(BATCH_SIZE)))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 3s 97ms/step - loss: 0.6429 - accuracy: 0.6180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6428672671318054, 0.6179999709129333]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(validationData, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# saving json format of model\n",
    "modelJSON = model.to_json()\n",
    "with open('cats_vs_dogs.json', 'w') as file:\n",
    "    file.write(modelJSON)\n",
    "    \n",
    "# saving weights of model\n",
    "model.save_weights(\"cats_vs_dogs_weights.h5\")\n",
    "\n",
    "#printing confirmation\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading model\n",
    "jsonFile = open('cats_vs_dogs.json', 'r')\n",
    "loadedJSONModel = jsonFile.read()\n",
    "jsonFile.close()\n",
    "loadedModel = K.models.model_from_json(loadedJSONModel)\n",
    "\n",
    "# loading weights using this model\n",
    "loadedModel.load_weights('cats_vs_dogs_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 3s 95ms/step - loss: 0.6429 - accuracy: 0.6180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6428672671318054, 0.6179999709129333]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compiling the loaded model\n",
    "loadedModel.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# evaluating the loaded model\n",
    "loadedModel.evaluate(validationData, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
